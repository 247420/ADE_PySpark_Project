{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5110c2da-274e-454f-8bc3-1e9a580a7278",
   "metadata": {},
   "source": [
    "# Fehlertoleranz der Spotify-Datenanalye\n",
    "\n",
    "## Einführung\n",
    "Fehlertoleranz ist ein zentraler Aspekt in verteilten Systemen wie Apache Spark. In diesem Notebook wird untersucht, wie robust diese Spark-Anwendung gegenüber Fehlern und Ausfällen ist.\n",
    "\n",
    "**Dabei betrachten wir drei Hauptaspekte:**\n",
    "\n",
    "- **1. Fehlertoleranz im Code**\n",
    "    - Bereits in der Implementierung wurden Maßnahmen ergriffen, um Fehler oder problematische Daten frühzeitig abzufangen.\n",
    "    - Beispielsweise wurden bestimmte Daten gefiltert oder Bereinigungen vorgenommen, um spätere Fehler zu vermeiden.\n",
    "    - Zudem nutzen einige Transformationen und Mechanismen von Spark bereits integrierte Fehlertoleranzmechanismen, die automatisch für eine stabilere Verarbeitung sorgen können.\n",
    "\n",
    "- **2. Fehlertoleranz-Test**\n",
    "    - Um die Stabilität der Spark-Anwendung zu bewerten, werden gezielt Fehlerfälle simuliert und ihr Einfluss auf die Anwendung analysiert.\n",
    " \n",
    "- **3. Weitere potentielle Fehlerszenarien** *(Am Ende des Notebooks)*\n",
    "\n",
    "Das **Ziel dieses Notebooks** ist es, besser zu verstehen, wie gut die Anwendung mit Fehlern umgehen kann und welche potenziellen Schwachstellen existieren.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7e1ec-f7a4-485b-b98d-ddfdddcfbd50",
   "metadata": {},
   "source": [
    "### 1. Fehlertoleranz beim Laden der Daten\n",
    "\n",
    "- **beschädigte Dateien** werden durch das `try-except` in der Funktion `process_pickle()`**abgefangen**.\n",
    "- Dabei werden **Standardwerte für fehlende Felder gesetzt**.\n",
    "- **Fehlerhafte Dateien** werden mit `\"track_uri\": None` **markiert**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db462f2f-07fd-4fb1-99df-fcd2cce235a2",
   "metadata": {},
   "outputs": [],
   "source": [
    " try:\n",
    "        with open(filepath, \"rb\") as file:\n",
    "            pickle_data = pickle.load(file)\n",
    "        return {\n",
    "            \"track_uri\": pickle_data.get(\"track_uri\", \"Unbekannt\"),\n",
    "            \"bars\": pickle_data.get(\"bars\", []),\n",
    "            \"duration_ms\": pickle_data.get(\"duration_ms\", \"Unbekannt\"),\n",
    "            \"sections\": pickle_data.get(\"sections\", []),\n",
    "            \"segments\": pickle_data.get(\"segments\", []),\n",
    "            \"loudness_max\": pickle_data.get(\"loudness_max\", \"Unbekannt\"),\n",
    "            \"keys\": pickle_data.get(\"keys\", []),\n",
    "            \"track\": pickle_data.get(\"track\", [])\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"track_uri\": None, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69c582-f310-44ef-a25d-9be2afe06689",
   "metadata": {},
   "source": [
    "### 2. Fehlertoleranz durch Debugging-Informationen  \n",
    "\n",
    "Um sicherzustellen, dass bei der Kombination von **CSV- und Pickle-Dateien** keine oder nur wenige Daten verloren gehen, wird die **Anzahl der Zeilen vor und nach der** `Join`-**Operation** gezählt.  \n",
    "\n",
    "Eine signifikante Abnahme der Zeilenanzahl könnte darauf hindeuten, dass die Werte in der Spalte `track_uri` nicht übereinstimmen. Da die **CSV-Daten bereits im initialen Schritt (Schritt 0)** sorgfältig bereinigt wurden, sollte dies normalerweise nicht auftreten.  \n",
    "\n",
    "Falls dennoch größere Abweichungen zwischen den Zeilen vor und nach dem Join festgestellt werden, könnte dies ein Hinweis darauf sein, dass der Pfad `csc_dir` auf eine **noch unbereinigte Datei** verweist.\n",
    "Des Weiteren wird in diesem Schritt durch die Zählung und anschließende Ausgabe der **erfolgreich sowie nicht verarbeiteten Dateien** für weitere Fehlertoleranz gesorgt.  \n",
    "\n",
    "Die zusätzliche Ausgabe der ersten Zeilen des kombinierten DataFrames hilft außerdem dabei, **mögliche Fehler im DataFrame** schon **vor komplexen und teuren Datenverarbeitungen frühzeitig zu identifizieren**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b47656-5db0-4fbd-989a-5f8396a3bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join-Information fürs Debugging\n",
    "print(f\"JOIN Information:\")\n",
    "print(f\"- Zeilen vor Join: {valid_pickle_df.count()}\")\n",
    "print(f\"- Zeilen nach Join: {combined_df.count()}\")\n",
    "\n",
    "# Statistik anzeigen\n",
    "total_files = len(pickle_files)\n",
    "successful_files = valid_pickle_df.count()\n",
    "failed_files = total_files - successful_files\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"Erfolgs-Statistik:\")\n",
    "print(f\"- Gesamtanzahl der Dateien: {total_files}\")\n",
    "print(f\"- Erfolgreich verarbeitet: {successful_files}\")\n",
    "print(f\"- Fehlerhaft: {failed_files}\")\n",
    "\n",
    "# Test, ob CSV und Pickle korrekt gejoint wurden: \n",
    "combined_df.select(\"track_uri\", \"track_uri_csv\", \"name\", \"duration_ms\").show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636e080-718b-4341-98c6-3ed0819d42ee",
   "metadata": {},
   "source": [
    "### 3. Fehlertoleranz bei der Berechnung des Dur-Prozentsatzes\n",
    "\n",
    "`F.when(combined_df[\"mode\"] == 1, 1).otherwise(0)` stellt sicher, dass nur die Werte 0 und 1 aufgenommen werden. **Sollte die Mode-Spalte andere Werte haben**, wird **keine Fehlermeldung** ausgegeben, sondern der Wert eindeutig eingeordnet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51129f2f-e748-4072-b5d8-4200c35770cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|major_percentage|\n",
      "+----------------+\n",
      "|            65.0|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df = combined_df.withColumn(\"is_major\", F.when(combined_df[\"mode\"] == 1, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74167abb-98bf-4832-8ac7-230949f90151",
   "metadata": {},
   "source": [
    "### 4. Fehlertoleranz bei der Datenvorbereitung für die Korrelation \n",
    "\n",
    "Um **Zeilen mit** `Null`-**Werten zu entfernen** und eine zuverlässige Berechnung der Korrelationswerten zu gewährleisten, wird die Filterfunktion `filter(isNotNull())` angewendet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef865fa9-35ea-4193-a61f-f3a355e32c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = exploded_df.filter((F.col(\"energy\").isNotNull()) & (F.col(\"danceability\").isNotNull()) & (F.col(\"loudness_max_segment\").isNotNull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2322a-2d53-4523-ab8b-5d4e0a501603",
   "metadata": {},
   "source": [
    "### Fehlertoleranz im Code - Fazit   \n",
    "\n",
    "Der Code hat gezielte Maßnahmen zur Fehlertoleranz implementiert, sodass keine unerwarteten Abstürze oder falschen Ergebnisse vorkommen sollten.   \n",
    "\n",
    "  - Explizite Datenbereinigung vor erstmaliger Ausführung\n",
    "  - Fehlerbehandlung bei Pickle-Dateien mit defekten oder fehlenden Daten, sodass der Prozess nicht unterbrochen wird\n",
    "  - Vermeidung von Null-Werten um Berechnungen zuverlässig durchzuführen\n",
    "  - Fehlerminimierung bei kritischen Operationen wie `explode()` oder `join()`: Ergänzung mit geeigneten Maßnahmen um z.B. Datenverlust zu reduzieren.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bda46f-9702-420e-8b8d-1035d992f943",
   "metadata": {},
   "source": [
    "## Fehlertoleranz-Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f2be7c5-f803-4282-80b9-29fbecf31038",
   "metadata": {},
   "source": [
    "### Testumgebung\n",
    "\n",
    "Da die lokale Ausführung der Spark-Anwendung nicht ausreichte, um realistische Fehlertoleranz-Szenarien zu testen, wurde stattdessen Spark im **Standalone-Modus** eingerichtet *(analog zur Anleitung aus dem Lab)*. \n",
    "\n",
    "<img src=\"../data/images/sparkcluster.png\" alt=\"Alle Worker aktiv\" width=\"600\">\n",
    "\n",
    "*Überblick der gestarteten Worker und Masters in der Spark-UI*\n",
    "\n",
    "Die folgenden Hard- und Software-Spezifikationen wurden für die Fehlertoleranz-Tests verwendet:  \n",
    "\n",
    "- **1 Master Node**\n",
    "- **4 Worker Nodes**\n",
    "    - **RAM**: 4 GB\n",
    "    - **CPU-Kerne**: 2\n",
    "\n",
    "<img src=\"../data/images/standaloneoverview.png\" alt=\"Alle Worker aktiv\" width=\"300\">\n",
    "\n",
    "*Ressourcen und Status des Clusters in der Master-UI*\n",
    "\n",
    "Wenn Größen im Test angepasst, verändert oder ganz weggelassen wurden, wurde dies explizit angegeben.\n",
    "\n", 
    "<img src=\"../data/images/workeralive.png\" alt=\"Alle Worker aktiv\" width=\"800\">\n",
    "\n",
    "*Alle erstellten Worker und ihre Ressourcen auf einem Blick in der Master-UI*\n",
    "\n",
    "## Zielsetzung\n",
    "Der Test soll zeigen, wie sich die Spark-Anwendung verhält, wenn:  \n",
    "1.  während einer Spark-Anwendung **Worker-Nodes ausfallen**\n",
    "2.  das **Netzwerk ausfällt**\n",
    "3.  **Worker-Nodes stark ungleichmäßig belastet werden**    \n",
    "\n",
    "Im weiteren Verlauf dieses Notebooks werden die Testergebnisse analysiert und visualisiert.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b8638-31cd-46fe-8a7e-09533a7f66d8",
   "metadata": {},
   "source": [
    "### **1. Fehlertoleranz-Test: Worker-Ausfall**\n",
    "\n",
    "Der erste Test untersucht die **Fehlertoleranz einer Spark-Anwendung**, wenn während der Laufzeit **Worker-Nodes ausfallen**. Ziel dieses Tests ist es, die Auswirkungen solcher plötzlichen Ausfälle zu analysieren und zu verstehen, wie Spark mit diesen umgeht.\n",
    "\n",
    "#### **Fragestellung**\n",
    "- **Was passiert, wenn Worker-Nodes in einer laufenden Spark-Anwendung ausfallen?**\n",
    "- **Kann die Anwendung den Betrieb stabil fortsetzen?**\n",
    "\n",
    "#### **Durchführung**\n",
    "In einem Experiment wurden **zwei Worker-Nodes deaktiviert**, während eine Spark-Anwendung bereits seit **1 Minute** mit **1000 Dateien** lief. Die Deaktivierung wurde simuliert, indem die entsprechenden **cmd-Fenster der Worker geschlossen** wurden.\n",
    "\n",
    "#### **Ergebnisse und Beobachtungen**\n",
    "\n",
    "1. **Normale Verarbeitung (alle Worker aktiv)**  \n",
    "   Zu Beginn des Tests waren alle **4 Worker aktiv**. Jeder Worker bearbeitete dabei **2 Tasks parallel**. Dies entsprach der ursprünglichen Konfiguration mit **2 CPU-Kernen pro Worker**.\n",
    "\n",
    "   <img src=\"../data/images/workerall.png\" alt=\"Alle Worker aktiv\" width=\"800\">\n",
    "\n",
    "   *Abbildung: Taskbearbeitung bei 4 aktiven Workern (je 2 parallele Tasks pro Worker)*\n",
    "\n",
    "2. **Ausfall von zwei Workern**  \n",
    "   Nach der Deaktivierung von zwei Workern wurden die laufenden Tasks der betroffenen Worker **fehlgeschlagen**. Diese fehlerhaften Tasks wurden jedoch automatisch von den verbleibenden Workern neu übernommen und erfolgreich beendet.\n",
    "\n",
    "   <img src=\"../data/images/workerloss1.png\" alt=\"Worker-Ausfall sichtbar\" width=\"600\">\n",
    "\n",
    "   *Abbildung: Ausfall von zwei Workern sichtbar in der Spark-UI*\n",
    "\n",
    "   <img src=\"../data/images/workerloss2.png\" alt=\"Fehlgeschlagene Tasks übernommen\" width=\"700\">\n",
    "\n",
    "   *Abbildung: Neuverteilung der fehlgeschlagenen Tasks auf die verbleibenden Worker*\n",
    "\n",
    "3. **Verarbeitung mit verbleibenden Workern**  \n",
    "   Nach dem Ausfall wurden **alle weiteren Tasks** von den **verbleibenden zwei Workern** bearbeitet. \n",
    "\n",
    "   <img src=\"../data/images/workerleft.png\" alt=\"Bearbeitung durch verbleibende Worker\" width=\"800\">\n",
    "\n",
    "   *Abbildung: Taskbearbeitung nach dem Ausfall - übrig gebliebene Worker übernehmen Workload von den ausgefallenen Workern*\n",
    "\n",
    "#### **Fazit**\n",
    "Der Test zeigt, dass die Spark-Anwendung nach einem **Worker-Ausfall stabil weiterläuft**, indem die fehlgeschlagenen Tasks auf die verbleibenden Worker verteilt werden. Allerdings verlängerte sich dadurch die Durchlaufzeit der Ausführung, da die Anzahl an parallelen Tasks pro Worker immernoch bei 2 Tasks blieb.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14544aa0-ea7a-4dfc-9ce4-58c681a3bcb4",
   "metadata": {},
   "source": [
    "### **2. Fehlertoleranz-Test: Netzwerk-Ausfall**\n",
    "\n",
    "#### **Fragestellungen:**  \n",
    "- Wie reagiert Spark, wenn die Verbindung zwischen einem Worker-Node und dem Master während der Laufzeit unterbrochen wird?  \n",
    "- Werden die betroffenen Tasks automatisch auf andere Worker umverteilt, sodass die Verarbeitung stabil fortgesetzt wird?  \n",
    "\n",
    "#### **Durchführung:**  \n",
    "In diesem Experiment wurde die Verbindung zwischen einem **Worker-Node** und dem **Master-Node** gezielt getrennt, während eine Spark-Anwendung bereits seit **3 Minuten mit 5000 Dateien** lief. Die Simulation des Netzwerkausfalls erfolgte über die gezielte **Beendigung des Worker-Prozesses** in der Windows-Kommandozeile.  \n",
    "\n",
    "Das Experiment wurde mit dem **gleichen Standalone-Spark-Cluster** durchgeführt, bestehend aus:  \n",
    "- **1 Master-Node**  \n",
    "- **4 Worker-Nodes**  \n",
    "- **Identischen Hardware- und Softwarekonfigurationen wie im ersten Test**  \n",
    "\n",
    "Um den Netzwerkausfall zu simulieren, wurde zunächst die **Portnummer des Workers** identifiziert, um darüber die **zugehörige Prozess-ID (PID)** zu bestimmen. Mithilfe der PID wurde dann der **Worker-Prozess während der Laufzeit gezielt beendet**, um eine Netzwerkunterbrechung zwischen Master und Worker nachzubilden.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69cd33-43be-41b2-a768-5ee914853ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taskkill /PID 7436 /F\n",
    "ERFOLGREICH: Der Prozess mit PID 7436 wurde beendet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c902506-ad55-4bee-a211-72282927ca68",
   "metadata": {},
   "source": [
    "#### **Ergebnisse und Beobachtungen**\n",
    "\n",
    "Die Ergebnisse dieses Experiments zeigen eine starke Übereinstimmung mit den Beobachtungen aus dem ersten Test. Auch hier wurde durch die **Simulation eines Netzwerkausfalls** gezielt ein **aktiver Worker während der Laufzeit entfernt**, um die Reaktion von Spark auf einen plötzlichen Verbindungsverlust zu analysieren.\n",
    "\n",
    "Wie bereits im vorherigen Experiment konnten vier Phasen identifiziert werden:\n",
    "\n",
    "1. **Normale Verarbeitung (alle Worker aktiv)**  \n",
    "   Zu Beginn des Tests waren alle **4 Worker aktiv**, und jeder bearbeitete **2 Tasks parallel**. Die Last war gleichmäßig verteilt, und alle Worker arbeiteten effizient zusammen.\n",
    "\n",
    "2. **Netzwerktrennung zwischen Master und einem Worker**  \n",
    "   Durch die simulierte Netzwerktrennung wurde die Kommunikation zwischen dem **Master und einem Worker** unterbrochen. Der Master konnte den Worker nicht mehr erreichen und markierte ihn als **DEAD**.\n",
    "\n",
    "   <img src=\"../data/images/networkloss.png\" alt=\"Fehlgeschlagene Tasks übernommen\" width=\"700\">\n",
    "\n",
    "   *Abbildung: Ausfall eines Workers sichtbar in der Master-UI*  \n",
    "    \n",
    "Alle laufenden Tasks auf diesem Worker sind **fehlgeschlagen**. Diese fehlgeschlagenen Tasks wurden automatisch von den verbleibenden Workern **übernommen und erfolgreich abgeschlossen**.  \n",
    "\n",
    "   <img src=\"../data/images/networkloss1.png\" alt=\"Fehlgeschlagene Tasks übernommen\" width=\"600\">\n",
    " \n",
    "   *Abbildung: Ausfall eines Workers sichtbar in der Spark-UI*  \n",
    "\n",
    "4. **Verarbeitung mit verbleibenden Workern**  \n",
    "   Nach dem Ausfall wurden **alle verbleibenden Tasks** von den verbliebenen **drei Workern** verarbeitet. Spark hat die Workload ohne Unterbrechung auf die verfügbaren Ressourcen umverteilt.\n",
    "\n",
    "#### **Fazit**  \n",
    "Dieses Experiment bestätigt erneut die **Fehlertoleranz von Apache Spark** gegenüber plötzlichen Worker-Ausfällen. Trotz der Netzwerktrennung kam es **weder zu einem Abbruch der Anwendung noch zu einem Datenverlust**.  \n",
    "- Spark hat den ausgefallenen Worker korrekt erkannt und die fehlgeschlagenen Tasks **automatisch auf andere Worker verteilt**.  \n",
    "- Die Verarbeitung lief **stabil weiter**, ohne dass ein manueller Eingriff erforderlich war.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cdbe8f-5d66-4197-806b-757203a1cc20",
   "metadata": {},
   "source": [
    "### **3. Fehlertoleranz-Test: Speicherbeschränkung eines Workers**\n",
    "\n",
    "#### **Fragestellung:**  \n",
    "- Wie reagiert Spark, wenn einem Worker im Cluster **deutlich weniger RAM** zur Verfügung steht als den anderen?  \n",
    "- Wird dieser Worker weiterhin für die Verarbeitung genutzt oder wird er mit der Zeit *abgehängt* werden?  \n",
    "\n",
    "#### **Durchführung:**  \n",
    "In diesem Experiment wurde einem der vier Worker bewusst **ein deutlich geringerer Speicher zugewiesen** als den anderen. Während drei Worker mit **4 GB RAM** konfiguriert wurden, erhielt der vierte Worker lediglich **512 MB RAM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d2da7-4285-40fa-a271-4b03cffd7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Worker 1: spark-class org.apache.spark.deploy.worker.Worker --cores 2 --memory 512M spark://localhost:7077\n",
    "Worker 2: spark-class org.apache.spark.deploy.worker.Worker --cores 2 --memory 4G spark://localhost:7077\n",
    "Worker 3: spark-class org.apache.spark.deploy.worker.Worker --cores 2 --memory 4G spark://localhost:7077\n",
    "Worker 4: spark-class org.apache.spark.deploy.worker.Worker --cores 2 --memory 4G spark://localhost:7077"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3cc148-5947-483b-874b-54fbeb7611b5",
   "metadata": {},
   "source": [
    "  #### **Beobachtungen:**  \n",
    "- Bereits vor der Ausführung der Spark-Anwendung wurde in der **Master UI** sichtbar, dass die konfigureierten Ressourcen des Workers (512 MB RAM und 2 Kerne)  als *\"Not Used\"* markiert wurde.\n",
    "\n",
    "   <img src=\"../data/images/notusedworker.png\" alt=\"Fehlgeschlagene Tasks übernommen\" width=\"700\">\n",
    "   \n",
    "    *trotz verfügbarer Ressourcen des Workers gibt Spark hier `0 Used` an (letzte Zeile)*\n",
    "\n",
    "- Während der Laufzeit der Anwendung führte **Spark keine Tasks auf diesem Worker aus**.  \n",
    "- In der **Spark UI** war ersichtlich, dass nur die drei Worker mit **4 GB RAM** aktiv Tasks bearbeiteten. Der vierte Worker wurde ignoriert.\n",
    "\n",
    "   <img src=\"../data/images/workernotused.png\" alt=\"Fehlgeschlagene Tasks übernommen\" width=\"600\">\n",
    "   \n",
    "    *3 Worker arbeiten an den Tasks - Worker 4 hat nicht mal eine Lane*\n",
    "\n",
    "- Wegen dieser unerwarteten Beobachtung, wurden nach Begründungen für dieses Verhalten des Systems gesucht.\n",
    "\n",
    "**--> Folgendes ist aufgefallen:**\n",
    "- Während bei dem Worker mit nur **512 MB RAM \"not Used\"** vermerkt war, stand bei den Workern mit 4 GB RAM nicht etwa *\"4 GB Used\"* sondern *\"1024 MB Used\"*. \n",
    "- Unter `Executor Memory - Default Resource Profile` wird außerdem der Wert **1024.0 MiB** angezeigt, was darauf hinweist, dass Spark standardmäßig mindestens **1 GB RAM pro Executor benötigt**.  \n",
    "- Da der Worker mit **512 MB RAM** diese Anforderung nicht erfüllte, wurde er von Spark **komplett ignoriert**.  \n",
    "\n",
    "#### **Fazit:**  \n",
    "Dieses Experiment zeigt, dass Spark **keine Worker verwendet, die die Mindestanforderung an `spark.executor.memory` nicht erfüllen**.  \n",
    "- Da die Standard-Einstellung für `spark.executor.memory` mindestens **1 GB (1024 MiB)** beträgt, wurde der Worker mit **nur 512 MB nicht berücksichtigt**.  \n",
    "- Um den Test erfolgreich durchführen zu können, muss der **Speicherbedarf pro Executor reduziert** werden. Dies kann durch die Konfiguration von `spark.executor.memory` erfolgen.\n",
    "\n",
    "**-->** ***Was wenn spark.executor.memory konfiguriert wurde - Wie reagiert Spark bei nun ungleichmäßier Belastung von Nodes?***\n",
    "\n",
    "Hätte das Experiment funktioniert wären sehr wahrscheinliche Ähnliche Mechanismen wie bei den ersten beiden Tests zu beobachten. Denn auch hier ist Spark fehlertolerant, indem er ungleichmäßige Last durch interne Mechanismen ausgleicht.\n",
    "\n",
    "**Task-Neuverteilung:** Wenn ein überlasteter Node langsamer wird oder ausfällt, übernimmt Spark automatisch die betroffenen Tasks auf andere verfügbare Nodes.  \n",
    "**Automatische Wiederherstellung:** Selbst bei stark ungleicher Last bleibt die Verarbeitung stabil, da Spark blockierte oder ausgefallene Tasks neu plant.  \n",
    "\n",
    "- Spark bleibt also auch bei ungleichmäßiger Belastung fehlertolerant!  \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e1823-0e80-4a27-acca-c0eeb040bb44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Weitere potenzielle Fehlerszenarien und deren Auswirkungen**\n",
    "\n",
    "Neben den getesteten Szenarien gibt es weitere mögliche Fehlerfälle, die in einer verteilten Spark-Anwendung auftreten können. Die Reaktion des Systems hängt stark von der Implementierung und den Konfigurationen ab.\n",
    "\n",
    "- **Master-Ausfall**  \n",
    "   - Falls der Spark-Master während der Laufzeit ausfällt, können **keine neuen Tasks mehr geplant** werden.  \n",
    "   - Bereits laufende Tasks auf den Workern werden weiter ausgeführt, aber neue Stages können nicht gestartet werden.  \n",
    "\n",
    "- **Out-of-Memory-Probleme bei Workern**  \n",
    "   - Falls ein Worker den Speicher überschreitet, schlägt der betroffene Task fehl, und Spark versucht ihn auf einem anderen Worker auszuführen.  \n",
    "   - Unser Code prüft bereits **Zeilenanzahlen nach Joins**, um große Datenverluste früh zu erkennen.  \n",
    "   - Eine präzisere Speichersteuerung durch bspw. **persist()** könnte helfen.  \n",
    "\n",
    "- **Fehlerhafte Eingabedateien**  \n",
    "   - Falls beschädigte oder unvollständige CSV- oder Pickle-Dateien vorliegen, kann dies zu unerwarteten Fehlern führen.  \n",
    "   - Unser Code erkennt solche Probleme teilweise durch **Zeilenüberprüfung nach Transformationen** und durch einen **try-except-Block für fehlerhafte Datei-Reads**\n",
    "   - Weitere Maßnahmen könnten **Validierungschecks auf Spaltennamen und Datentypen** sein.  \n",
    "\n",
    "- **Langsame oder nicht erreichbare externe Datenquellen**  \n",
    "   - Falls eine externe Datenquelle nicht erreichbar ist, kann die Anwendung blockieren oder fehlschlagen.  \n",
    "   - Unser Code würde dies aktuell nicht direkt abfangen, aber **Retry-Mechanismen oder alternative Datenquellen** könnten die Fehlertoleranz verbessern.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
